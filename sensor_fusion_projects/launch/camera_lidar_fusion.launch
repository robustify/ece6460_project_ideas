<?xml version="1.0"?>

<launch>

  <arg name="cam_ns" default="/sensors/camera/flir/stereo/left" />
  <arg name="run_darknet" default="false" />

  <include file="$(find dataset_playback)/launch/dataset_playback.launch" >
    <arg name="cepton_enabled" value="true" />
    <arg name="stereo_cam_enabled" value="true" />
  </include>

  <!-- Example node to get bounding boxes in an image corresponding to LIDAR clusters -->
  <node pkg="sensor_fusion_projects" type="lidar_obj_projection" name="lidar_obj_projection" output="screen" >
    <param name="cam_ns" value="$(arg cam_ns)" />
  </node>

  <!-- Provided version of Homework 4 object tracking -->
  <include file="$(find avs_lecture_sensor_config)/launch/euclidean_clustering.launch" >
    <arg name="raw_points_topic" value="/sensors/lidar/cepton/points" />
  </include>

  <!-- YOLO classification -->
  <include file="$(find yolo_classification)/launch/yolo_classification.launch" >
    <arg name="run_darknet" value="$(arg run_darknet)" />
    <arg name="camera_name" value="$(arg cam_ns)" />
  </include>

  <node pkg="rviz" type="rviz" name="camera_lidar_fusion_viz" args="-d $(find sensor_fusion_projects)/rviz/camera_lidar.rviz" respawn="true" />

</launch>
