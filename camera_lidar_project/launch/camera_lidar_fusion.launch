<?xml version="1.0"?>

<launch>

  <arg name="cam_ns" default="/sensors/camera/flir/stereo/left" />
  <arg name="raw_points_topic" default="/sensors/lidar/cepton/points" />
  <arg name="run_darknet" default="false" />

  <include file="$(find dataset_playback)/launch/dataset_playback.launch" >
    <arg name="stereo_cam_enabled" value="true" />
    <arg name="traffic_cam_enabled" value="false" />
    <arg name="rviz" value="false" />
    <arg name="tf_config_file" value="$(find camera_lidar_project)/yaml/sensor_tf_config.yaml" />
  </include>

  <!-- Example node to get bounding boxes in an image corresponding to LIDAR clusters -->
  <node pkg="camera_lidar_project" type="camera_lidar_project" name="camera_lidar_fusion" output="screen" >
    <param name="cam_ns" value="$(arg cam_ns)" />
  </node>

  <!-- Provided version of Homework 4 object tracking -->
  <include file="$(find avs_lecture_sensor_config)/launch/euclidean_clustering.launch" >
    <arg name="raw_points_topic" value="$(arg raw_points_topic)" />
  </include>

  <!-- YOLO classification -->
  <include file="$(find yolo_classification)/launch/yolo_classification.launch" >
    <arg name="run_darknet" value="$(arg run_darknet)" />
    <arg name="camera_name" value="$(arg cam_ns)" />
  </include>

  <node pkg="rviz" type="rviz" name="camera_lidar_fusion_viz" args="-d $(find camera_lidar_project)/rviz/rviz_config.rviz" respawn="true" />

  <node pkg="rqt_image_view" type="rqt_image_view" name="lidar_projection" args="/output_image" />
  <node pkg="rqt_image_view" type="rqt_image_view" name="yolo_classification" args="$(arg cam_ns)/yolo_image" />

</launch>
